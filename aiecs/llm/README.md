# LLM Package - æ¨¡å—åŒ– AI æä¾›å•†æ¶æ„

## ğŸ“¦ åŒ…ç»“æ„

```
aiecs/llm/
â”œâ”€â”€ __init__.py              # ä¸»å…¥å£ï¼Œå¯¼å‡ºæ‰€æœ‰å…¬å…± API
â”œâ”€â”€ client_factory.py        # å®¢æˆ·ç«¯å·¥å‚å’Œç®¡ç†å™¨
â”œâ”€â”€ clients/                 # LLM å®¢æˆ·ç«¯å®ç°
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_client.py       # åŸºç¡€å®¢æˆ·ç«¯æŠ½è±¡ç±»
â”‚   â”œâ”€â”€ openai_client.py     # OpenAI å®¢æˆ·ç«¯
â”‚   â”œâ”€â”€ vertex_client.py     # Vertex AI å®¢æˆ·ç«¯
â”‚   â”œâ”€â”€ googleai_client.py   # Google AI å®¢æˆ·ç«¯
â”‚   â””â”€â”€ xai_client.py        # xAI (Grok) å®¢æˆ·ç«¯
â”œâ”€â”€ config/                  # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ model_config.py      # Pydantic é…ç½®æ¨¡å‹
â”‚   â”œâ”€â”€ config_loader.py     # é…ç½®åŠ è½½å™¨
â”‚   â””â”€â”€ config_validator.py  # é…ç½®éªŒè¯å™¨
â”œâ”€â”€ callbacks/               # å›è°ƒå¤„ç†
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ custom_callbacks.py  # è‡ªå®šä¹‰å›è°ƒå¤„ç†å™¨
â””â”€â”€ utils/                   # å·¥å…·å’Œè„šæœ¬
    â”œâ”€â”€ __init__.py
    â””â”€â”€ validate_config.py   # é…ç½®éªŒè¯è„šæœ¬
```

## ğŸ”Œ å…¬å…± APIï¼ˆå¯¹å¤–æ¥å£ï¼‰

### âœ… æ¨èçš„å¯¼å…¥æ–¹å¼ï¼ˆå‘åå…¼å®¹ï¼‰

æ‰€æœ‰å…¬å…± API éƒ½å¯ä»¥ä» `aiecs.llm` ç›´æ¥å¯¼å…¥ï¼š

```python
# åŸºç¡€ç±»å’Œç±»å‹
from aiecs.llm import (
    BaseLLMClient,
    LLMMessage,
    LLMResponse,
    LLMClientError,
    ProviderNotAvailableError,
    RateLimitError,
    AIProvider
)

# å®¢æˆ·ç«¯å®ç°
from aiecs.llm import (
    OpenAIClient,
    VertexAIClient,
    GoogleAIClient,
    XAIClient
)

# å·¥å‚å’Œç®¡ç†å™¨
from aiecs.llm import (
    LLMClientFactory,
    LLMClientManager,
    get_llm_manager
)

# ä¾¿æ·å‡½æ•°
from aiecs.llm import generate_text, stream_text

# é…ç½®ç®¡ç†ï¼ˆæ–°å¢ï¼‰
from aiecs.llm import (
    ModelCostConfig,
    ModelCapabilities,
    ModelConfig,
    ProviderConfig,
    LLMModelsConfig,
    get_llm_config_loader,
    reload_llm_config
)

# å›è°ƒå¤„ç†
from aiecs.llm import CustomAsyncCallbackHandler
```

### âš ï¸ å†…éƒ¨æ¨¡å—è·¯å¾„å˜åŒ–

å¦‚æœä»£ç ç›´æ¥ä»å­æ¨¡å—å¯¼å…¥ï¼ˆä¸æ¨èï¼‰ï¼Œéœ€è¦æ›´æ–°è·¯å¾„ï¼š

**æ—§è·¯å¾„ï¼ˆå·²åºŸå¼ƒï¼‰ï¼š**
```python
from aiecs.llm.base_client import BaseLLMClient          # âŒ
from aiecs.llm.vertex_client import VertexAIClient       # âŒ
from aiecs.llm.custom_callbacks import CustomAsyncCallbackHandler  # âŒ
```

**æ–°è·¯å¾„ï¼š**
```python
from aiecs.llm.clients.base_client import BaseLLMClient
from aiecs.llm.clients.vertex_client import VertexAIClient
from aiecs.llm.callbacks.custom_callbacks import CustomAsyncCallbackHandler
```

**æœ€ä½³å®è·µï¼ˆæ¨èï¼‰ï¼š**
```python
from aiecs.llm import BaseLLMClient, VertexAIClient, CustomAsyncCallbackHandler
```

## ğŸ“ è¿ç§»æŒ‡å—

### ä¸éœ€è¦æ›´æ”¹çš„ä»£ç 

ä»¥ä¸‹ä»£ç **æ— éœ€ä»»ä½•ä¿®æ”¹**ï¼Œå®Œå…¨å‘åå…¼å®¹ï¼š

```python
# âœ… è¿™äº›å¯¼å…¥æ–¹å¼ä¿æŒä¸å˜
from aiecs.llm import VertexAIClient, OpenAIClient
from aiecs.llm import LLMClientFactory, AIProvider
from aiecs.llm import LLMMessage, LLMResponse
from aiecs.llm import get_llm_manager

# âœ… ä½¿ç”¨æ–¹å¼ä¹Ÿå®Œå…¨ä¸å˜
client = LLMClientFactory.get_client("OpenAI")
manager = await get_llm_manager()
```

### éœ€è¦æ›´æ”¹çš„ä»£ç ï¼ˆæå°‘æƒ…å†µï¼‰

åªæœ‰ç›´æ¥å¯¼å…¥å­æ¨¡å—çš„ä»£ç éœ€è¦æ›´æ–°ï¼š

```python
# âŒ æ—§ä»£ç 
from aiecs.llm.base_client import BaseLLMClient

# âœ… æ–¹æ¡ˆ 1ï¼šä½¿ç”¨æ–°çš„å†…éƒ¨è·¯å¾„
from aiecs.llm.clients.base_client import BaseLLMClient

# âœ… æ–¹æ¡ˆ 2ï¼šä»ä¸»æ¨¡å—å¯¼å…¥ï¼ˆæ¨èï¼‰
from aiecs.llm import BaseLLMClient
```

## ğŸ¯ æœ€ä½³å®è·µ

1. **å§‹ç»ˆä»ä¸»æ¨¡å—å¯¼å…¥**
   ```python
   from aiecs.llm import VertexAIClient  # âœ… æ¨è
   ```

2. **é¿å…å¯¼å…¥å†…éƒ¨æ¨¡å—**
   ```python
   from aiecs.llm.clients.vertex_client import VertexAIClient  # âš ï¸ ä¸æ¨è
   ```

3. **ä½¿ç”¨å·¥å‚æ¨¡å¼**
   ```python
   from aiecs.llm import LLMClientFactory
   client = LLMClientFactory.get_client("Vertex")  # âœ… æ¨è
   ```

## ğŸ†• æ–°å¢åŠŸèƒ½

### é…ç½®ç®¡ç†

ç°åœ¨å¯ä»¥é€šè¿‡ YAML é…ç½®æ–‡ä»¶ç®¡ç†æ‰€æœ‰æ¨¡å‹ï¼š

```python
from aiecs.llm import get_llm_config_loader, reload_llm_config

# è·å–é…ç½®åŠ è½½å™¨
loader = get_llm_config_loader()

# è·å–æ¨¡å‹é…ç½®
model_config = loader.get_model_config("OpenAI", "gpt-4-turbo")
print(f"æˆæœ¬: è¾“å…¥ ${model_config.costs.input}, è¾“å‡º ${model_config.costs.output}")

# çƒ­é‡è½½é…ç½®ï¼ˆæ— éœ€é‡å¯åº”ç”¨ï¼‰
reload_llm_config()
```

### é…ç½®éªŒè¯

```bash
# éªŒè¯é…ç½®æ–‡ä»¶
poetry run python -m aiecs.llm.utils.validate_config
```

## ğŸ“š ç¤ºä¾‹

æŸ¥çœ‹å®Œæ•´ç¤ºä¾‹ï¼š
- `examples/llm_config_example.py` - é…ç½®ç®¡ç†ç¤ºä¾‹
- `docs/LLM/LLM_CONFIGURATION.md` - é…ç½®æ–‡æ¡£

## ğŸ”„ å‘åå…¼å®¹æ€§

æœ¬æ¬¡é‡æ„**100% å‘åå…¼å®¹**ï¼š
- âœ… æ‰€æœ‰å…¬å…± API ä¿æŒä¸å˜
- âœ… ç°æœ‰ä»£ç æ— éœ€ä¿®æ”¹
- âœ… å¯¼å…¥è·¯å¾„ä¿æŒä¸€è‡´
- âœ… åŠŸèƒ½è¡Œä¸ºå®Œå…¨ç›¸åŒ

å”¯ä¸€çš„å˜åŒ–æ˜¯å†…éƒ¨æ–‡ä»¶ç»„ç»‡ç»“æ„ï¼Œä½†è¿™å¯¹ä½¿ç”¨è€…é€æ˜ã€‚

## ğŸ“– æ›´å¤šæ–‡æ¡£

- [é…ç½®ç®¡ç†æ–‡æ¡£](../../docs/LLM/LLM_CONFIGURATION.md)
- [å®¢æˆ·ç«¯æ–‡æ¡£](../../docs/LLM/LLM_AI_CLIENTS.md)
- [å›è°ƒæ–‡æ¡£](../../docs/LLM/LLM_CUSTOM_CALLBACKS.md)

